python:
    1.1 python基本的数据结构和特点
    1.2 深拷贝浅拷贝出现的原因和解决办法
    1.3 常用的自带库内的数据结构和应用场景
    1.4 内存管理
    1.5 多进程和多线程

pytorch：
    2.1 pytorch模型训练梯度更新的流程
    2.2 pytorch的DistributedDataParallel和DataParallel的联系和区别

机器学习部分：
    3.1 LR在二分类时，生成两个概率和生成一个概率用阈值截断有什么不同
    3.2 PCA和LR,SVM有什么区别和联系
    3.3 LR在二分类情况下的loss
    3.4 多分类场景的常用loss
    3.5 GBDT和xgboost的原理是什么
    3.6 决策树和LR哪一个泛化性能更好，为什么 
    3.7 强化学习有了解过吗 
    3.8 正则化，L1正则和L2正则的联系和区别

深度学习部分：
    4.1 文本生成：
        4.1.1 Transformer在训练时decoder过程如何避免模型看到当前position后面的内容
        4.1.2 如果涉及到多语种的问题，有一些语言的corpus很小，有什么解决办法
        4.1.3 有什么可控的生成手段，比如生成商家或者商品的推荐语想要突出某些特点,前提是要保证生成内容的可靠性
        4.1.4 采用了哪些策略来实现多样化的文本生成，具体是怎么做的
        4.1.5 生成长文本的时候比较容易出现某些句子发生重复，怎么解决
        4.1.6 有什么评估生成质量的方法
        4.1.7 Decorder有什么解码策略
    4.2 知识图谱：
        4.2.1 知识图谱的表示学习有什么方法，优缺点
        4.2.2 从0开始建一个知识图谱的流程是怎样的，你会使用哪些技术
        4.2.3 如何评估知识图谱表示学习的好坏？
        4.2.4 采用更大的训练数据和模型体量，知识图谱的表示学习你是否遇到了瓶颈
        4.2.5 知识图谱的表示学习最近自己有什么想法或者创新点么
    4.3 关系抽取
